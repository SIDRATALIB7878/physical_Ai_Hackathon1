Physical AI & Humanoid Robotics Capstone Project Target audience: AI students and robotics enthusiasts Focus: Physical AI, embodied intelligence, humanoid robot simulation and deployment Scope: Apply AI to control humanoid robots via ROS 2, Gazebo, NVIDIA Isaac, and GPT-based conversational robotics Success criteria: * Design and deploy humanoid robots in simulation and/or real-world * Demonstrate ROS 2 control (nodes, topics, services) * Implement physics simulation (Gazebo/Unity) * Use Isaac Sim for perception, navigation, and manipulation * Integrate voice commands and LLM-based planning * Reproducible results on simulated and physical platforms * Technical claims supported by credible sources Constraints: * Word count: 10k–15k * Format: Markdown for Docusaurus * Citations: APA style, ≥50% official/peer-reviewed sources * Timeline: 13-week hackathon quarter * Not building: Full hardware lab, commercial comparisons, pricing details, non-technical ethics Modules: 1. Robotic Nervous System (ROS 2) – nodes, topics, services, rclpy, URDF 2. Digital Twin (Gazebo & Unity) – physics, sensors, high-fidelity rendering 3. AI-Robot Brain (NVIDIA Isaac) – Isaac Sim, Isaac ROS, VSLAM, path planning 4. Vision-Language-Action (VLA) – Whisper, LLM planning, multimodal interaction 5. Capstone – Autonomous Humanoid: command → plan → navigate → perceive → manipulate Hardware/Software: * Workstation: RTX 4070 Ti+, Ubuntu 22.04, 64GB RAM * Edge AI kit: Jetson Orin Nano/NX, RealSense D435i, USB mic * Optional robot: Unitree Go2/G1 or budget alternatives * Cloud simulation allowed (AWS RoboMaker/Omniverse) Deliverables: * ROS 2 packages * Gazebo/Unity simulations * Isaac ROS perception and navigation pipelines * Voice-command humanoid integration * Markdown documentation with APA citations